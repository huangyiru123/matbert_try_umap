{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6ee9ae-9c2c-4cb5-9c3c-2a533ca9c87f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/customer/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "from transformers import BertConfig, BertModel, BertTokenizer\n",
    "from transformers import BertForMaskedLM, BertTokenizerFast, pipeline\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from bert_serving.client import BertClient\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c496ead2-b230-49a4-aa07-0f3b1db01353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = BertConfig.from_json_file(\"config.json\")\n",
    "model = BertForMaskedLM.from_pretrained('/home/customer/hyr/matbert-uncased（copy-version）')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('/home/customer/hyr/matbert-uncased（copy-version）', do_lower_case=False)\n",
    "# unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b9859-f006-4d14-aca7-1b9ea67d4214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 输入单词 并将其转换为token\n",
    "input_text = \"perovskite is used in [MASK]\"\n",
    "input_ids = tokenizer.encode(input_text, add_special_tokens=False, return_tensors='pt')\n",
    "\n",
    "# 使用模型预测mask位置的token的隐藏状态\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "# 提取 \"perovskite\" 对应的词向量\n",
    "mask_index = (input_ids == tokenizer.mask_token_id).nonzero()[0, 1]  # 获取 \"MASK\" token 的索引\n",
    "word_logits = outputs.logits[0, mask_index]\n",
    "\n",
    "print(\"词向量：\", word_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "299f12f7-91f5-4723-9954-6d5b3c1020e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词向量： tensor([-9.9807, -6.4048, -6.3191,  ..., -6.8940, -5.5510, -4.5033])\n"
     ]
    }
   ],
   "source": [
    "# 输入单词 并将其转换为token\n",
    "input_text = \"perovskite is used in [MASK]\"\n",
    "input_ids = tokenizer.encode(input_text, add_special_tokens=False, return_tensors='pt')\n",
    "\n",
    "# 使用模型预测mask位置的token的隐藏状态\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "# 提取 \"perovskite\" 对应的词向量\n",
    "mask_index = (input_ids == tokenizer.mask_token_id).nonzero()[0, 1]  # 获取 \"MASK\" token 的索引\n",
    "word_logits = outputs.logits[0, mask_index]\n",
    "\n",
    "print(\"词向量：\", word_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b034b82d-0395-4e98-8395-ef5e941f17bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 获取BERT模型的词汇表\n",
    "vocab = tokenizer.get_vocab()\n",
    "vocab_list = list(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6f8f1e7-cf1a-4f85-8271-9b81869e4620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 选择一部分词汇进行可视化，或者使用全部词汇也可以\n",
    "num_words_to_visualize = 10000\n",
    "vocab_list_subset = vocab_list[:num_words_to_visualize]\n",
    "\n",
    "\n",
    "# 如果你想要可视化全部词向量↓\n",
    "# vocab_list_subset = vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e0b6059-6c6c-4e79-8909-9d6ca9b60cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 获取词汇的词向量\n",
    "embeddings = []\n",
    "for word in vocab_list_subset:\n",
    "    token_id = tokenizer(word, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=token_id)\n",
    "        embeddings.append(output[0].mean(dim=1).numpy())\n",
    "\n",
    "embeddings_np = np.concatenate(embeddings, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e33cae-2c50-4e36-8c94-23a0303cddd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.cluster import MiniBatchKMeans\n",
    "# 使用MiniBatchKMeans进行聚类\n",
    "# num_clusters = 10\n",
    "# kmeans = MiniBatchKMeans(n_clusters=num_clusters)\n",
    "# cluster_labels = kmeans.fit_predict(embeddings_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373067da-cdf6-41e9-a2db-2518d6b18180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "# 使用UMAP进行降维\n",
    "reducer = UMAP()\n",
    "embeddings_umap = reducer.fit_transform(embeddings_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf59466-c9ca-4073-9b01-9e6277e25d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 选取要高亮的词汇\n",
    "highlight_words = ['material']\n",
    "# 绘制可视化图\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(num_clusters):\n",
    "    plt.scatter(embeddings_umap[cluster_labels == i, 0], embeddings_umap[cluster_labels == i, 1], label=f'Cluster {i}')\n",
    "\n",
    "# 高亮显示指定的词汇\n",
    "highlight_indices = [vocab_list_subset.index(word) for word in highlight_words]\n",
    "highlight_embeddings = embeddings_umap[highlight_indices]\n",
    "plt.scatter(highlight_embeddings[:, 0], highlight_embeddings[:, 1], color='red', marker='o', label='Highlighted Words')\n",
    "for i, word in zip(highlight_indices, highlight_words):\n",
    "    plt.text(embeddings_umap[i, 0], embeddings_umap[i, 1], word, fontsize=10)\n",
    "\n",
    "plt.legend()\n",
    "plt.title('UMAP Visualization of BERT Word Embeddings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45491b0d-fe40-4b02-8e8f-f7bce5c3a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_words = ['material']\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# 绘制聚类点\n",
    "for i in range(num_clusters):\n",
    "    plt.scatter(embeddings_umap[cluster_labels == i, 0], embeddings_umap[cluster_labels == i, 1], color='gray', label=f'Cluster {i}')\n",
    "\n",
    "# 高亮显示指定的词汇\n",
    "highlight_embeddings = embeddings_umap[highlight_indices]\n",
    "plt.scatter(highlight_embeddings[:, 0], highlight_embeddings[:, 1], color='blue', marker='o', label='Highlighted Words')\n",
    "for i, word in zip(highlight_indices, highlight_words):\n",
    "    plt.text(embeddings_umap[i, 0], embeddings_umap[i, 1], word, fontsize=10)\n",
    "\n",
    "plt.legend()\n",
    "plt.title('UMAP Visualization of BERT Word Embeddings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde4dd5-e7ad-43e9-9e3b-b9aa09fdf3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分界线----------------------以下不要kmean了-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71fdd3a-68ea-4370-98cb-492d03c9b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取BERT模型的词汇表\n",
    "vocab = tokenizer.get_vocab()\n",
    "vocab_list = list(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20388f9-554d-4ff0-a9e0-baf8f43f08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择一部分词汇进行可视化，或者使用全部词汇也可以\n",
    "num_words_to_visualize = 10000\n",
    "vocab_list_subset = vocab_list[:num_words_to_visualize]\n",
    "\n",
    "\n",
    "# 如果你想要可视化全部词向量↓\n",
    "# vocab_list_subset = vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6200b-444b-49d3-a102-3880c360ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取词汇的词向量\n",
    "embeddings = []\n",
    "for word in vocab_list_subset:\n",
    "    token_id = tokenizer(word, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=token_id)\n",
    "        embeddings.append(output[0].mean(dim=1).numpy())\n",
    "\n",
    "embeddings_np = np.concatenate(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939b03b7-76c0-409b-a18e-d71de492b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "# 使用UMAP进行降维\n",
    "reducer = UMAP()\n",
    "embeddings_umap = reducer.fit_transform(embeddings_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9d2e5-e8fd-4a98-82d7-997d89302be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Words to highlight in blue\n",
    "blue_highlight_words = ['perovskite', 'word1', 'word2']\n",
    "\n",
    "# Words to highlight in green\n",
    "green_highlight_words = ['word3', 'word4', 'word5']\n",
    "\n",
    "# Words to highlight in yellow\n",
    "yellow_highlight_words = ['word6', 'word7', 'word8']\n",
    "\n",
    "# Function to determine color based on word\n",
    "def get_color(word):\n",
    "    if word in blue_highlight_words:\n",
    "        return 'blue'\n",
    "    elif word in green_highlight_words:\n",
    "        return 'green'\n",
    "    elif word in yellow_highlight_words:\n",
    "        return 'yellow'\n",
    "    else:\n",
    "        return 'gray'\n",
    "\n",
    "# Plot the embeddings\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, word in enumerate(vocab_list_subset):\n",
    "    color = get_color(word)\n",
    "    plt.scatter(embeddings_umap[i, 0], embeddings_umap[i, 1], c=color)\n",
    "    if color != 'gray':\n",
    "        plt.text(embeddings_umap[i, 0], embeddings_umap[i, 1], word, fontsize=9, color=color)\n",
    "plt.title('UMAP Visualization of Word Embeddings')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4adc363-6829-44b9-a5e0-e25ec523f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------新分界线---下面要画渐变色图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ddb888-62dd-42f4-ac46-e91e0718bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to compute cosine similarity between vectors\n",
    "def cosine_similarity_vec(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a73c8a6-f1dd-4093-bd86-585cebb24d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between \"perovskite\" and all other words\n",
    "perovskite_embedding = None\n",
    "perovskite_index = None\n",
    "for i, word in enumerate(vocab_list_subset):\n",
    "    if word == \"perovskite\":\n",
    "        perovskite_embedding = embeddings_np[i]\n",
    "        perovskite_index = i\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860467e-338c-4f3a-ba54-99715bf3fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = []\n",
    "for i, embedding in enumerate(embeddings_np):\n",
    "    if i != perovskite_index:\n",
    "        similarity = cosine_similarity_vec(perovskite_embedding, embedding)\n",
    "        cosine_similarities.append((i, similarity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554a945-01a2-42df-ab55-fe3f2c4796bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort cosine similarities by value and get the top 1000\n",
    "cosine_similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "top_similarities = cosine_similarities[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b654e5-e63a-4fa5-9a30-9e0feb013e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract words and similarities\n",
    "top_words = [vocab_list_subset[i[0]] for i in top_similarities]\n",
    "top_values = [i[1] for i in top0_similarities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794832e-1be9-49f8-8c95-202af96f356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the embeddings with cosine similarity as color\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(embeddings_umap[:, 0], embeddings_umap[:, 1], c=top_1000_values, cmap='Purples', alpha=0.6)\n",
    "\n",
    "# Highlight 'HTL' and 'ETL' with star markers\n",
    "htl_index = vocab_list_subset.index('HTL')\n",
    "etl_index = vocab_list_subset.index('ETL')\n",
    "plt.scatter(embeddings_umap[htl_index, 0], embeddings_umap[htl_index, 1], c='red', marker='*', label='HTL')\n",
    "plt.scatter(embeddings_umap[etl_index, 0], embeddings_umap[etl_index, 1], c='blue', marker='*', label='ETL')\n",
    "\n",
    "plt.colorbar(label='Cosine Similarity')\n",
    "plt.title('UMAP Visualization of Word Embeddings with Cosine Similarity to \"perovskite\"')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.legend()\n",
    "plt.savefig('colorful.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
